{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza00000/data/blob/main/Folder_Copier_Google_Drive_and_Mega14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCJikoACNzLh"
      },
      "source": [
        "# **Google Drive Operations**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QtYoh9HeD5ZJ"
      },
      "outputs": [],
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYQtz80XvuhAXEQD6TyNc9B2fO3MVwiwcKQJJtfypvTYaTYwg4PdOPjy5exHRy0pfCevzuq8d0xVi1evLVcxrA74XjcGug=s1600' alt=\"GoogleDrive-logo\"/></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "d3KAxlFQ4N4K"
      },
      "outputs": [],
      "source": [
        "#@markdown Copy Files & Folders\n",
        "import os\n",
        "\n",
        "To_Copy = \"\" #@param {type:\"string\"}\n",
        "Destination1 = \"\" #@param {type:\"string\"}\n",
        "File_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "is_folder = 'Yes' #@param [\"Yes\", \"No\"]\n",
        "unzip_file = 'No' #@param [\"Yes\", \"No\"]\n",
        "extension = \"zip\" #@param [\"zip\", \"rar\", \"tar\", \"iso\"]\n",
        "\n",
        "Destination = \"/content/\" + Destination1\n",
        "\n",
        "try:\n",
        "  os.makedirs(Destination, exist_ok = True)\n",
        "except OSError as error:\n",
        "  print(\"Directory can not be created.\")\n",
        "\n",
        "if is_folder == \"Yes\":\n",
        "  tc1 = To_Copy + \"/\"\n",
        "  !sudo cp -v -r \"$tc1\" \"$Destination\"\n",
        "else:\n",
        "  tc1 = To_Copy\n",
        "  tc2 = Destination + \"/\"\n",
        "  tc3 = Destination + \"/\" + File_name + \".\" + extension\n",
        "  !sudo cp -v -r \"$tc1\" \"$tc3\"\n",
        "\n",
        "if is_folder == \"No\":\n",
        "  if unzip_file == \"Yes\":\n",
        "    if extension == \"zip\":\n",
        "      !unzip -q \"$tc3\" -d \"$tc2\"\n",
        "    elif extension == \"rar\":\n",
        "      !unrar x \"$tc3\" \"$tc2\"\n",
        "    elif extension == \"tar\":\n",
        "      !tar -xvf \"$tc3\" \"$tc2\"\n",
        "    elif extension == \"iso\":\n",
        "      !7z x -o{\"$tc2\"} \"$tc3\"\n",
        "\n",
        "    !rm \"$tc3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N5ycUyZeXCAY"
      },
      "outputs": [],
      "source": [
        "#@markdown Size of Folders\n",
        "import os\n",
        "\n",
        "path1 = \"/content/GTA 5\" #@param {type:\"string\"}\n",
        "def get_size(start_path =  path1):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(start_path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            # skip if it is symbolic link\n",
        "            if not os.path.islink(fp):\n",
        "                total_size += os.path.getsize(fp)\n",
        "\n",
        "    return total_size\n",
        "\n",
        "by = get_size()\n",
        "k_b = by/1024\n",
        "m_b = k_b/1024\n",
        "g_b = m_b/1024\n",
        "\n",
        "print(by, 'bytes')\n",
        "print(k_b, 'kilobytes')\n",
        "print(m_b, 'megabytes')\n",
        "print(g_b, 'gigabytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X0wY0hgRYMS0"
      },
      "outputs": [],
      "source": [
        "#@markdown Delete Folders\n",
        "import shutil\n",
        "\n",
        "dir_path = \"/content/FIFA 18\" #@param {type:\"string\"}\n",
        "\n",
        "try:\n",
        "    shutil.rmtree(dir_path)\n",
        "except OSError as e:\n",
        "    print(\"Error: %s : %s\" % (dir_path, e.strerror))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ZIP File\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zip_path = \"\" #@param {type:\"string\"}\n",
        "store_path = \"\" #@param {type:\"string\"}\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "ff = store_path + \"/\" + file_name\n",
        "\n",
        "# Create object of ZipFile\n",
        "with ZipFile(ff, 'w') as zip_object:\n",
        "   # Traverse all files in directory\n",
        "   for folder_name, sub_folders, file_names in os.walk(zip_path):\n",
        "      for filename in file_names:\n",
        "         # Create filepath of files in directory\n",
        "         file_path = os.path.join(folder_name, filename)\n",
        "         # Add files to zip file\n",
        "         zip_object.write(file_path, os.path.basename(file_path))\n",
        "\n",
        "if os.path.exists(ff):\n",
        "   print(\"ZIP file created\")\n",
        "else:\n",
        "   print(\"ZIP file not created\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SH8hjIKe05A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bM39zUBFTqOg"
      },
      "outputs": [],
      "source": [
        "#@markdown Extract ZIP File\n",
        "from zipfile import ZipFile\n",
        "\n",
        "file_path = \"\" #@param {type:\"string\"}\n",
        "dir_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "extension = \"zip\" #@param [\"zip\", \"rar\", \"tar\", \"iso\"]\n",
        "delete_file = 'No' #@param [\"Yes\", \"No\"]\n",
        "\n",
        "tc2 = dir_path + \"/\"\n",
        "tc3 = file_path\n",
        "\n",
        "if extension == \"zip\":\n",
        "  !unzip -q \"$tc3\" -d \"$tc2\"\n",
        "elif extension == \"rar\":\n",
        "  !unrar x \"$tc3\" \"$tc2\"\n",
        "elif extension == \"tar\":\n",
        "  !tar -xvf \"$tc3\" \"$tc2\"\n",
        "elif extension == \"iso\":\n",
        "  !7z x -o{\"$tc2\"} \"$tc3\"\n",
        "\n",
        "if delete_file == \"Yes\":\n",
        "  !rm \"$tc3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q0bvjs2pt41"
      },
      "source": [
        "# **Open Two Google Drives**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRNFcOFoXbA"
      },
      "outputs": [],
      "source": [
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnVguotyoyNZ"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd /content\n",
        "!mkdir drive1\n",
        "%cd drive1\n",
        "!mkdir MyDrive\n",
        "%cd ..\n",
        "%cd ..\n",
        "!google-drive-ocamlfuse /content/drive1/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt_RqPgONgLl"
      },
      "source": [
        "#**MEGA to Google Drive Copier**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cXkTIKqMM-qw"
      },
      "outputs": [],
      "source": [
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYSnbtqgh0TukRqTUyaVSaFnN_qL1cMCA6RzSwLy9qB-bkS1urf-337FSN_xYQJs9TzVoHrCGbnHLRkM24wDpbjUrFLKGw=s1600' alt=\"MEGA-logo\"/></center>\n",
        "\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        ")\n",
        "\n",
        "MegaUrl = \"\" #@param {type:\"string\"}\n",
        "TransferLocationOfGdrive = \"\" #@param {type:\"string\"}\n",
        "if not TransferLocationOfGdrive:\n",
        "  os.makedirs(\"downloads\", exist_ok=True)\n",
        "  TransferLocationOfGdrive = \"downloads\"\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    loadingAn()\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "    clear_output()\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "\n",
        "def transfare():\n",
        "    import codecs\n",
        "    decoder = codecs.getincrementaldecoder(\"UTF-8\")()\n",
        "    cmd = [\"mega-get\", MegaUrl, TransferLocationOfGdrive]\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        print(line)\n",
        "\n",
        "\n",
        "\n",
        "transfare()\n",
        "\n",
        "time.sleep(3)\n",
        "print(\"Completed\")\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-mB4NsurqE3"
      },
      "source": [
        "# **OneDrive to Google Drive**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z61Yaa5pr0Ge"
      },
      "outputs": [],
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYSAJVLlMTUxPHCLnN37M9SCNpdrFMZ2q_95uq-pk82-xRt1PGHVbOEG38en-2dL9m9SZgiqcWU3zF1euwX2c2d63ZtzIA=s1600' alt=\"OneDrive-logo\"/></center>\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "\n",
        "site_link = \"\"  #@param {type:\"string\"}\n",
        "destination = \"\"  #@param {type:\"string\"}\n",
        "name = \"\"  #@param {type:\"string\"}\n",
        "excel_file = 'No' #@param [\"Yes\", \"No\"]\n",
        "\n",
        "Sheet_Path = \"\" #@param {type:\"string\"}\n",
        "Sheet_Name = \"\" #@param {type:\"string\"}\n",
        "Zip_Files = 'No' #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if excel_file == \"Yes\":\n",
        "  link_file = pd.read_excel(Sheet_Path, Sheet_Name)\n",
        "\n",
        "  if Zip_Files == \"Yes\":\n",
        "    for x in link_file.id:\n",
        "      InputUrl = link_file.link1[x]+\".zip\"\n",
        "      OutputDir = link_file.location[x]+\".zip\"\n",
        "\n",
        "      try:\n",
        "        os.makedirs(link_file.location[x], exist_ok = True)\n",
        "      except OSError as error:\n",
        "        print(\"Directory can not be created.\")\n",
        "\n",
        "      split_url = InputUrl.rfind('?')\n",
        "      converted_url = InputUrl[:split_url] + '?download=1'\n",
        "\n",
        "      !wget -O \"$OutputDir\" \"$converted_url\"\n",
        "\n",
        "      with ZipFile(OutputDir, 'r') as zip:\n",
        "        zip.extractall(link_file.location[x])\n",
        "\n",
        "      os.remove(OutputDir)\n",
        "      print('Done!')\n",
        "      print(' ')\n",
        "\n",
        "  else:\n",
        "    for x in link_file.id:\n",
        "      InputUrl = link_file.link1[x]\n",
        "      OutputDir = link_file.location[x]+\"/\"+str(link_file.name[x])\n",
        "      OutputDirr = link_file.location[x]+\"/\"\n",
        "\n",
        "      try:\n",
        "        os.makedirs(link_file.location[x], exist_ok = True)\n",
        "      except OSError as error:\n",
        "        print(\"Directory can not be created.\")\n",
        "\n",
        "      split_url = InputUrl.rfind('?')\n",
        "      converted_url = InputUrl[:split_url] + '?download=1'\n",
        "\n",
        "      !wget -O \"$OutputDir\" -P \"$OutputDirr\" \"$converted_url\"\n",
        "\n",
        "      print('Done!')\n",
        "      print(' ')\n",
        "\n",
        "else:\n",
        "  InputUrl = site_link\n",
        "  OutputDir = destination+\"/\"+name\n",
        "  OutputDirr = destination+\"/\"\n",
        "\n",
        "  split_url = InputUrl.rfind('?')\n",
        "  converted_url = InputUrl[:split_url] + '?download=1'\n",
        "\n",
        "  !wget -O \"$OutputDir\" -P \"$OutputDirr\" \"$converted_url\"\n",
        "\n",
        "  print('Done!')\n",
        "  print(' ')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Install RClone & 7-Zip\n",
        "\n",
        "!wget https://downloads.rclone.org/v1.62.2/rclone-v1.62.2-linux-amd64.deb\n",
        "!apt install ./rclone-v1.62.2-linux-amd64.deb\n",
        "!sudo apt-get -y install fuse3\n",
        "\n",
        "!wget https://www.7-zip.org/a/7z2201-linux-x64.tar.xz\n",
        "!mkdir /content/7zip\n",
        "!sudo tar -xf 7z2201-linux-x64.tar.xz -C \"/content/7zip\"\n",
        "!mv /content/7zip/7zz /usr/local/bin\n",
        "\n",
        "!rm 7z2201-linux-x64.tar.xz\n",
        "!rm rclone-v1.62.2-linux-amd64.deb\n",
        "!rm -rf /content/7zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MiYhHoqMDcay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown RClone Config\n",
        "\n",
        "!rclone config\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/root/.rclone.conf')"
      ],
      "metadata": {
        "id": "2zbWu8Qghkb7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown RClone Config Upload\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "source = files.upload()\n",
        "\n",
        "!cp rclone.conf /root/\n",
        "!mv /root/rclone.conf /root/.rclone.conf\n",
        "!mv rclone.conf /root/.config/rclone"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OA_uOTBkLuyC",
        "outputId": "86b98c22-baf5-4146-dc7e-91adf03c6a89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-accf772e-93e6-48fd-9f0d-ed121067746d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-accf772e-93e6-48fd-9f0d-ed121067746d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rclone.conf to rclone.conf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown List Directories\n",
        "\n",
        "drive = \"onedrive2\" #@param {type:\"string\"}\n",
        "\n",
        "dr1 = drive + \":\"\n",
        "\n",
        "!rclone lsd \"$dr1\""
      ],
      "metadata": {
        "id": "9e-mXdqRb_J-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download Folders\n",
        "\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "url_link = \"\" #@param {type:\"string\"}\n",
        "raw_data = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!wget --post-data \"$raw_data\" -O \"$file_name\" \"$url_link\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "aF_FB4TOy0qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download Folders in Background\n",
        "\n",
        "file_name = \"\" #@param {type:\"string\"}\n",
        "url_link = \"\" #@param {type:\"string\"}\n",
        "raw_data = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!rm nohup.out\n",
        "!nohup wget --post-data \"$raw_data\" -O \"$file_name\" \"$url_link\" &"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8IQnSVCux2j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Extract 7-Zip Files\n",
        "\n",
        "file_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "!7zz x \"$file_path\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "V01rLkUvJPrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Copy Folders to OneDrive\n",
        "\n",
        "To_Copy = \"Cricket 22\" #@param {type:\"string\"}\n",
        "remote_name = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote_name +  \":\" + To_Copy\n",
        "add_drive = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if add_drive == \"Yes\":\n",
        "  tc1 = \"/content/drive/MyDrive/\" + To_Copy\n",
        "else:\n",
        "  tc1 = \"/content/\" + To_Copy\n",
        "\n",
        "!rclone copy -v --stats 5s \"$tc1\" \"$Destination\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "tXReuZgSRCaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Copy Folders from OneDrive\n",
        "\n",
        "To_Copy = \"Torrent\" #@param {type:\"string\"}\n",
        "remote_name = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote_name +  \":\" + To_Copy\n",
        "add_drive = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if add_drive == \"Yes\":\n",
        "  tc1 = \"/content/drive/MyDrive/\" + To_Copy\n",
        "else:\n",
        "  tc1 = \"/content/\" + To_Copy\n",
        "\n",
        "!rclone copy -v --stats 5s \"$Destination\" \"$tc1\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "SnaATOQcEn7i",
        "outputId": "a1950109-18da-45d0-e0f8-79e72c22385d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024/11/06 06:04:22 INFO  : There was nothing to transfer\n",
            "2024/11/06 06:04:22 INFO  : \n",
            "Transferred:   \t          0 B / 0 B, -, 0 B/s, ETA -\n",
            "Checks:                52 / 52, 100%\n",
            "Elapsed time:         2.5s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Background Copy Folders to OneDrive\n",
        "\n",
        "To_Copy = \"Torrent\" #@param {type:\"string\"}\n",
        "remote_name = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote_name +  \":\" + To_Copy\n",
        "add_drive = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if add_drive == \"Yes\":\n",
        "  tc1 = \"/content/drive/MyDrive/\" + To_Copy\n",
        "else:\n",
        "  tc1 = \"/content/\" + To_Copy\n",
        "\n",
        "!rm nohup.out\n",
        "!nohup rclone copy -v --stats 5s \"$tc1\" \"$Destination\" &"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IOj65sZgC-iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Background Copy Folders from OneDrive\n",
        "\n",
        "To_Copy = \"Torrent\" #@param {type:\"string\"}\n",
        "remote_name = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote_name +  \":\" + To_Copy\n",
        "add_drive = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if add_drive == \"Yes\":\n",
        "  tc1 = \"/content/drive/MyDrive/\" + To_Copy\n",
        "else:\n",
        "  tc1 = \"/content/\" + To_Copy\n",
        "\n",
        "!rm nohup.out\n",
        "!nohup rclone copy -v --stats 5s \"$Destination\" \"$tc1\" &"
      ],
      "metadata": {
        "cellView": "form",
        "outputId": "37af183b-431f-433e-f601-72df4a9de2db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHfVq5jtCkBM"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'nohup.out': No such file or directory\n",
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sync Folders to OneDrive\n",
        "\n",
        "To_Copy = \"\" #@param {type:\"string\"}\n",
        "remote_name = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote_name +  \":\" + To_Copy\n",
        "add_drive = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "if add_drive == \"Yes\":\n",
        "  tc1 = \"/content/drive/MyDrive/\" + To_Copy\n",
        "else:\n",
        "  tc1 = \"/content/\" + To_Copy\n",
        "\n",
        "!rclone sync -v --stats 5s \"$tc1\" \"$Destination\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "5_ASj4PjkJM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Copy Folders Between Remote Drives\n",
        "\n",
        "remote1 = \"onedrive\" #@param {type:\"string\"}\n",
        "folder_name = \"\" #@param {type:\"string\"}\n",
        "tc1 = remote1 + \":\" + folder_name\n",
        "\n",
        "remote2 = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote2 + \":\" + folder_name\n",
        "\n",
        "!rclone copy -v --stats 5s \"$tc1\" \"$Destination\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "KAXH_vBuelGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Background Copy Folders Between Remote Drives\n",
        "\n",
        "remote1 = \"onedrive\" #@param {type:\"string\"}\n",
        "folder_name = \"\" #@param {type:\"string\"}\n",
        "tc1 = remote1 + \":\" + folder_name\n",
        "\n",
        "remote2 = \"onedrive2\" #@param {type:\"string\"}\n",
        "Destination = remote2 + \":\" + folder_name\n",
        "\n",
        "!rm nohup.out\n",
        "!nohup rclone copy -v --stats 5s \"$tc1\" \"$Destination\" &"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t1xavDKxRo7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Mount OneDrive\n",
        "\n",
        "!sudo mkdir /content/onedrive\n",
        "!nohup rclone --vfs-cache-mode writes mount onedrive: /content/onedrive &"
      ],
      "metadata": {
        "id": "vijRoCDjdAoz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Copy Folders using RSync\n",
        "import os\n",
        "\n",
        "To_Copy = \"\" #@param {type:\"string\"}\n",
        "Destination = \"/content/onedrive/\" + To_Copy\n",
        "\n",
        "tc1 = \"/content/\" + To_Copy\n",
        "\n",
        "try:\n",
        "  os.makedirs(Destination, exist_ok = True)\n",
        "except OSError as error:\n",
        "  print(\"Directory can not be created.\")\n",
        "\n",
        "!rsync --ignore-existing --recursive --info=progress2 \"$tc1\" \"$Destination\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "LYvOlJN2gSUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "augFsr6_aXF5"
      },
      "source": [
        "# **Torrent to Google Drive**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9JdIMtGPaMeG"
      },
      "outputs": [],
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYT5LP9ksvJlXxhTA8-53Rj8hyYTwZEvi1Cfrf8fVE1FwaouA7KIuiXuKlBPd5jmhtei50QsZPgOFJEG2P1X_Pt7HFmbkA=s1600' alt=\"Bittorent-logo\"/></center>\n",
        "\n",
        "#@markdown Install Library\n",
        "\n",
        "!python -m pip install --upgrade pip setuptools wheel\n",
        "!python -m pip install lbry-libtorrent\n",
        "!apt install python3-libtorrent\n",
        "\n",
        "import libtorrent as lt\n",
        "\n",
        "ses = lt.session()\n",
        "ses.listen_on(6881, 6891)\n",
        "downloads = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ykJj06pHeqrv"
      },
      "outputs": [],
      "source": [
        "#@markdown Upload Torrent\n",
        "from google.colab import files\n",
        "\n",
        "source = files.upload()\n",
        "params = {\n",
        "    \"save_path\": \"/content/drive/MyDrive/Torrent\",\n",
        "    \"ti\": lt.torrent_info(list(source.keys())[0]),\n",
        "}\n",
        "downloads.append(ses.add_torrent(params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "meXGjD2RiIzY"
      },
      "outputs": [],
      "source": [
        "#@markdown Magnet Link Download\n",
        "params = {\"save_path\": \"/content/drive/MyDrive/Torrent\"}\n",
        "\n",
        "while True:\n",
        "    magnet_link = input(\"Enter Magnet Link Or Type Exit: \")\n",
        "    if magnet_link.lower() == \"exit\":\n",
        "        break\n",
        "    downloads.append(\n",
        "        lt.add_magnet_uri(ses, magnet_link, params)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zhZcK7MgiHS7"
      },
      "outputs": [],
      "source": [
        "#@markdown Start Download\n",
        "import time\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "state_str = [\n",
        "    \"queued\",\n",
        "    \"checking\",\n",
        "    \"downloading metadata\",\n",
        "    \"downloading\",\n",
        "    \"finished\",\n",
        "    \"seeding\",\n",
        "    \"allocating\",\n",
        "    \"checking fastresume\",\n",
        "]\n",
        "\n",
        "layout = widgets.Layout(width=\"auto\")\n",
        "style = {\"description_width\": \"initial\"}\n",
        "download_bars = [\n",
        "    widgets.FloatSlider(\n",
        "        step=0.01, disabled=True, layout=layout, style=style\n",
        "    )\n",
        "    for _ in downloads\n",
        "]\n",
        "display(*download_bars)\n",
        "\n",
        "while downloads:\n",
        "    next_shift = 0\n",
        "    for index, download in enumerate(downloads[:]):\n",
        "        bar = download_bars[index + next_shift]\n",
        "        if not download.is_seed():\n",
        "            s = download.status()\n",
        "\n",
        "            bar.description = \" \".join(\n",
        "                [\n",
        "                    download.name(),\n",
        "                    str(s.download_rate / 1000),\n",
        "                    \"kB/s\",\n",
        "                    state_str[s.state],\n",
        "                ]\n",
        "            )\n",
        "            bar.value = s.progress * 100\n",
        "        else:\n",
        "            next_shift -= 1\n",
        "            ses.remove_torrent(download)\n",
        "            downloads.remove(download)\n",
        "            bar.close() # Seems to be not working in Colab (see https://github.com/googlecolab/colabtools/issues/726#issue-486731758)\n",
        "            download_bars.remove(bar)\n",
        "            print(download.name(), \"complete\")\n",
        "    time.sleep(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3x1DpmWjwZ3"
      },
      "source": [
        "# **Any Download Link**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UQjyRnccj2it"
      },
      "outputs": [],
      "source": [
        "#@markdown Place File Extension Also\n",
        "direct_URL = \"https://firebasestorage.googleapis.com/v0/b/cricket-22-goldberg-017.appspot.com/o/Cricket_22_GoldBerg.zip?alt=media&token=a4eea23e-d200-48c7-905e-0a89bd4df93d\" #@param {type:\"string\"}\n",
        "name = \"Cricket.zip\" #@param {type:\"string\"}\n",
        "\n",
        "output_dir = \"/content/\" + name\n",
        "\n",
        "!wget -O \"$output_dir\" \"$direct_URL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFulYXtSZCuB"
      },
      "source": [
        "# **Udemy Downloader**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mcEi_Rnrci0X"
      },
      "outputs": [],
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYRrfc3Q8PmwPa6hOw6C2iIIMpeMVt7Vz778nVzi_nCuTR9K9bxdUR-XycsgTCec4Fyq5a1YyYORbzjmXOmQLhuaFXQU=s1600' alt=\"Udemy-logo\"/></center>\n",
        "\n",
        "#@markdown Install Library\n",
        "\n",
        "!pip install --upgrade youtube-dl\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hthhcJsIbN_w"
      },
      "outputs": [],
      "source": [
        "#@markdown Download Course\n",
        "\n",
        "cookies_path = \"\" #@param {type:\"string\"}\n",
        "output_path = \"\" #@param {type:\"string\"}\n",
        "udemy_link = \"\" #@param {type:\"string\"}\n",
        "folder_name = \"\" #@param {type:\"string\"}\n",
        "\n",
        "file_name = \"%(chapter_number)s - %(chapter)s/%(playlist_index)s. %(title)s.%(ext)s\"\n",
        "outf = output_path + \"/\" + folder_name + \"/\" + file_name\n",
        "\n",
        "split_url1 = udemy_link.rfind('/')\n",
        "converted_url1 = udemy_link[:split_url1]\n",
        "split_url2 = converted_url1.rfind('/')\n",
        "converted_url2 = \"https://www.udemy.com\" + converted_url1[split_url2:] + \"/\"\n",
        "\n",
        "!youtube-dl --write-sub --sub-lang en --cookies \"$cookies_path\" -o \"$outf\" -i \"$converted_url2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AZbyHwu80gsx"
      },
      "outputs": [],
      "source": [
        "#@markdown Download Courses From Excel File\n",
        "\n",
        "cookies_path = \"\" #@param {type:\"string\"}\n",
        "output_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "Sheet_Path = \"\" #@param {type:\"string\"}\n",
        "Sheet_Name = \"\" #@param {type:\"string\"}\n",
        "link_file = pd.read_excel(Sheet_Path, Sheet_Name)\n",
        "\n",
        "file_name = \"%(chapter_number)s - %(chapter)s/%(playlist_index)s. %(title)s.%(ext)s\"\n",
        "\n",
        "for x in link_file.id:\n",
        "  udemy_link = link_file.link1[x]\n",
        "  folder_name = link_file.location[x]\n",
        "\n",
        "  outf = output_path + \"/\" + folder_name + \"/\" + file_name\n",
        "\n",
        "  split_url1 = udemy_link.rfind('/')\n",
        "  converted_url1 = udemy_link[:split_url1]\n",
        "  split_url2 = converted_url1.rfind('/')\n",
        "  converted_url2 = \"https://www.udemy.com\" + converted_url1[split_url2:] + \"/\"\n",
        "\n",
        "  !youtube-dl --write-sub --sub-lang en --cookies \"$cookies_path\" -o \"$outf\" -i \"$converted_url2\"\n",
        "\n",
        "  print(' ')\n",
        "  print('Done!')\n",
        "  print(' ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YouTube Downloader**"
      ],
      "metadata": {
        "id": "TQsbRfkqPOo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYRuPzpzEnZ8Q_6oDUxqv3Ect3Kh4vX8vSLZukOUQXzNTXZbunPQIfGy5Ge0tLqjfBRUoW5WlvLrHxzAX9Gmvg99ZjK95g=s1600' alt=\"Youtube-logo\"/></center>\n",
        "\n",
        "#@markdown Install Library\n",
        "\n",
        "!pip install --upgrade youtube-dl\n",
        "!pip install --upgrade yt-dlp\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vrAlvlhxPISE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download Videos From Excel File\n",
        "\n",
        "output_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "Sheet_Path = \"\" #@param {type:\"string\"}\n",
        "Sheet_Name = \"\" #@param {type:\"string\"}\n",
        "downloader = 'yt-dlp' #@param [\"youtube-dl\", \"yt-dlp\"]\n",
        "format = 'mp4' #@param {type:\"string\"}\n",
        "link_file = pd.read_excel(Sheet_Path, Sheet_Name)\n",
        "\n",
        "for x in link_file.id1:\n",
        "  url = link_file.link1[x]\n",
        "  outf = output_path + \"/\" + Sheet_Name + \"/\" + link_file.name1[x] + \".%(ext)s\"\n",
        "\n",
        "  txt = \"Downloading \" +str(x+1)+\" of \"+str(max(link_file.id1)+1)+\"...\"\n",
        "  print(txt)\n",
        "\n",
        "  if downloader == \"yt-dlp\":\n",
        "    !yt-dlp -f \"$format\" -o \"$outf\" -i \"$url\"\n",
        "  else:\n",
        "    !youtube-dl -f \"$format\" -o \"$outf\" -i \"$url\"\n",
        "\n",
        "  print(' ')\n",
        "  print('Done!')\n",
        "  print(' ')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pA52dwCPPNHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Download Playlist\n",
        "\n",
        "output_path = \"\" #@param {type:\"string\"}\n",
        "\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "playlist_name = \"\" #@param {type:\"string\"}\n",
        "downloader = 'yt-dlp' #@param [\"youtube-dl\", \"yt-dlp\"]\n",
        "format = 'mp4' #@param {type:\"string\"}\n",
        "\n",
        "file_name = \"%(playlist_index)s. %(title)s.%(ext)s\"\n",
        "outf = output_path + \"/\" + playlist_name + \"/\" + file_name\n",
        "\n",
        "if downloader == \"yt-dlp\":\n",
        "  !yt-dlp -f \"$format\" -o \"$outf\" -i --yes-playlist \"$url\"\n",
        "else:\n",
        "  !youtube-dl -f \"$format\" -o \"$outf\" -i \"$url\"\n",
        "\n",
        "print(' ')\n",
        "print('Done!')\n",
        "print(' ')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gYsosngDKY5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PDF Operations**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "6fMvdFDQNoY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYTauCYHv2O-g7ckkBa6gkNp_j1hvbFmQDAlRmw98wZidNtOMOVeowmsJzUaUf2C40LwVopwzHw7qiRGRm7V5O4S1QcHNA=s1600' alt=\"adobepdf-logo\"/></center>\n",
        "\n",
        "#@markdown Install Library\n",
        "!pip install pdfkit\n",
        "!sudo apt-get install wkhtmltopdf\n",
        "!sudo apt-get install xvfb\n",
        "!printf '#!/bin/bash\\nxvfb-run -a --server-args=\"-screen 0, 1920x1080x24\" /usr/bin/wkhtmltopdf -q $*' > /usr/bin/wkhtmltopdf.sh\n",
        "!chmod a+x /usr/bin/wkhtmltopdf.sh\n",
        "!ln -s /usr/bin/wkhtmltopdf.sh /usr/local/bin/wkhtmltopdf\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DCP4uRObAd6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Install Arabic Font\n",
        "!sudo apt-add-repository universe\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install fonts-hosny-amiri"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Awu1iIzJlTj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Create PDFs\n",
        "import pdfkit\n",
        "\n",
        "site = \"\"  #@param {type:\"string\"}\n",
        "destination = \"\"  #@param {type:\"string\"}\n",
        "iterations =  None #@param {type:\"integer\"}\n",
        "start = None  #@param {type:\"integer\"}\n",
        "single_site = 'No' #@param [\"Yes\", \"No\"]\n",
        "images = 'Yes' #@param [\"Yes\", \"No\"]\n",
        "excel_file = 'Yes' #@param [\"Yes\", \"No\"]\n",
        "one_folder = 'Yes' #@param [\"Yes\", \"No\"]\n",
        "Sheet_Path = \"\" #@param {type:\"string\"}\n",
        "Sheet_Name = \"\" #@param {type:\"string\"}\n",
        "trailing = \"\" #@param {type:\"string\"}\n",
        "y = start\n",
        "\n",
        "if images == \"Yes\":\n",
        "  op = {\n",
        "      'page-size': 'A4',\n",
        "      'load-error-handling': 'ignore'\n",
        "  }\n",
        "else:\n",
        "  op = {\n",
        "      'page-size': 'A4',\n",
        "      'no-images':None,\n",
        "      'load-error-handling': 'ignore'\n",
        "  }\n",
        "\n",
        "if excel_file == \"Yes\":\n",
        "  import pandas as pd\n",
        "  import os\n",
        "  link_file = pd.read_excel(Sheet_Path, Sheet_Name)\n",
        "\n",
        "  if one_folder == \"Yes\":\n",
        "    OutputDir = destination + \"/\" + Sheet_Name\n",
        "\n",
        "    try:\n",
        "      os.makedirs(OutputDir, exist_ok = True)\n",
        "    except OSError as error:\n",
        "      print(\"Directory can not be created.\")\n",
        "\n",
        "    for z in link_file.id:\n",
        "\n",
        "      iter = int(link_file.page1[z])\n",
        "\n",
        "      txt = \"Creating \" +str(z+1)+\" of \"+str(max(link_file.id)+1)+\"...\"\n",
        "      print(txt)\n",
        "\n",
        "      for x in range(iter):\n",
        "        site2 = link_file.link1[z] + \"/\" + link_file.name1[z] + trailing\n",
        "        dest2 = OutputDir + \"/\" + link_file.name1[z] + \".pdf\"\n",
        "\n",
        "        pdfkit.from_url(site2,dest2, options=op)\n",
        "\n",
        "      print(' Done! ')\n",
        "      print(' ')\n",
        "\n",
        "  else:\n",
        "\n",
        "    for z in link_file.id:\n",
        "\n",
        "      OutputDir = destination + \"/\" + link_file.name1[z]\n",
        "      iter = int(link_file.page1[z])\n",
        "\n",
        "      txt = \"Creating \" +str(z+1)+\" of \"+str(max(link_file.id)+1)+\"...\"\n",
        "      print(txt)\n",
        "\n",
        "      try:\n",
        "        os.makedirs(OutputDir, exist_ok = True)\n",
        "      except OSError as error:\n",
        "        print(\"Directory can not be created.\")\n",
        "\n",
        "      for x in range(iter):\n",
        "        site2 = link_file.link1[z] + \"/\" + str(x+1) + trailing\n",
        "        dest2 = OutputDir + \"/\" + str(x+1) + \".pdf\"\n",
        "\n",
        "        pdfkit.from_url(site2,dest2, options=op)\n",
        "\n",
        "      print(' Done! ')\n",
        "      print(' ')\n",
        "\n",
        "else:\n",
        "\n",
        "    if single_site == \"Yes\":\n",
        "      site2 = site\n",
        "      dest2 = destination + \"/\" + \"webpage.pdf\"\n",
        "\n",
        "      pdfkit.from_url(site2,dest2, options=op)\n",
        "    else:\n",
        "      for x in range(iterations):\n",
        "        site2 = site + \"/\" + str(y)\n",
        "        dest2 = destination + \"/\" + str(y)+\".pdf\"\n",
        "\n",
        "        pdfkit.from_url(site2,dest2, options=op)\n",
        "        y = y+1"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SXv_7mZABmG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Merge PDFs\n",
        "from pypdf import PdfReader\n",
        "from pypdf import PdfWriter\n",
        "\n",
        "source = \"\"  #@param {type:\"string\"}\n",
        "iterations =  None #@param {type:\"integer\"}\n",
        "start = None  #@param {type:\"integer\"}\n",
        "remove_end_pages = None  #@param {type:\"integer\"}\n",
        "excel_file = 'Yes' #@param [\"Yes\", \"No\"]\n",
        "Sheet_Path = \"\" #@param {type:\"string\"}\n",
        "Sheet_Name = \"\" #@param {type:\"string\"}\n",
        "y = start\n",
        "\n",
        "if excel_file == \"Yes\":\n",
        "  import pandas as pd\n",
        "\n",
        "  link_file = pd.read_excel(Sheet_Path, Sheet_Name)\n",
        "\n",
        "  for z in link_file.id:\n",
        "    OutputDir = source + \"/\" + link_file.name1[z]\n",
        "    iter = int(link_file.page1[z])\n",
        "\n",
        "    txt = \"Merging \" +str(z+1)+\" of \"+str(max(link_file.id)+1)+\"...\"\n",
        "    print(txt)\n",
        "\n",
        "    merger = PdfWriter()\n",
        "\n",
        "    for x in range(iter):\n",
        "      source2 = OutputDir + \"/\" + str(x+1) + \".pdf\"\n",
        "      reader = PdfReader(source2)\n",
        "\n",
        "      meta = reader.metadata\n",
        "      p = len(reader.pages)-remove_end_pages\n",
        "\n",
        "      input1 = open(source2, \"rb\")\n",
        "      merger.append(fileobj=input1, pages=(0, p))\n",
        "\n",
        "    dest2 = OutputDir + \".pdf\"\n",
        "    merger.write(dest2)\n",
        "    merger.close()\n",
        "\n",
        "    print(' Done! ')\n",
        "    print(' ')\n",
        "\n",
        "else:\n",
        "  merger = PdfWriter()\n",
        "\n",
        "  for x in range(iterations):\n",
        "    source2 = source + \"/\" + str(y) + \".pdf\"\n",
        "    reader = PdfReader(source2)\n",
        "\n",
        "    meta = reader.metadata\n",
        "    p = len(reader.pages)-remove_end_pages\n",
        "\n",
        "    input1 = open(source2, \"rb\")\n",
        "    merger.append(fileobj=input1, pages=(0, p))\n",
        "    y = y+1\n",
        "\n",
        "  dest2 = source + \"/\" + \"merged-pdf.pdf\"\n",
        "  merger.write(dest2)\n",
        "  merger.close()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WosuMfCKL4Op"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown PDF Compression\n",
        "from pypdf import PdfReader, PdfWriter\n",
        "\n",
        "location = \"\"  #@param {type:\"string\"}\n",
        "pdf_file = \"\"  #@param {type:\"string\"}\n",
        "conv_type = 'Lossless Compression' #@param [\"Remove Duplicates\", \"Remove Images\", \"Lossless Compression\"]\n",
        "\n",
        "reader = PdfReader(source)\n",
        "writer = PdfWriter()\n",
        "\n",
        "if conv_type == \"Remove Duplicates\":\n",
        "  for page in reader.pages:\n",
        "    writer.add_page(page)\n",
        "  writer.add_metadata(reader.metadata)\n",
        "  dest2 = location + \"/\" + \"duplicates-removed.pdf\"\n",
        "elif conv_type == \"Remove Images\":\n",
        "  for page in reader.pages:\n",
        "    writer.add_page(page)\n",
        "  writer.remove_images()\n",
        "  dest2 = location + \"/\" + \"images-removed.pdf\"\n",
        "elif conv_type == \"Lossless Compression\":\n",
        "  for page in reader.pages:\n",
        "    page.compress_content_streams()  # This is CPU intensive!\n",
        "    writer.add_page(page)\n",
        "  dest2 = location + \"/\" + \"lossless-compression.pdf\"\n",
        "\n",
        "source = location + \"/\" + pdf_file\n",
        "f = open(dest2, \"w\")\n",
        "f.close()\n",
        "with open(dest2, \"wb\") as fp:\n",
        "    writer.write(fp)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dIObT1mwW-NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Video Converter**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ZxE2ffZ1L85p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown <br><center><img src='https://lh3.googleusercontent.com/drive-viewer/AEYmBYTauCYHv2O-g7ckkBa6gkNp_j1hvbFmQDAlRmw98wZidNtOMOVeowmsJzUaUf2C40LwVopwzHw7qiRGRm7V5O4S1QcHNA=s1600' alt=\"adobepdf-logo\"/></center>\n",
        "\n",
        "#@markdown Install Library\n",
        "!sudo apt install ffmpeg\n",
        "!ffmpeg -version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MZflkKUqLScY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "data = []\n",
        "oo = []\n",
        "\n",
        "folder = \"Torrent/Ben.10.Ultimate.Alien.S01.1080p.HMAX.WEBRip.DD.2.0.x265-EDGE2020\"  #@param {type:\"string\"}\n",
        "output_folder = \"S1\"  #@param {type:\"string\"}\n",
        "extension = \"mkv\"  #@param {type:\"string\"}\n",
        "convert_to = \"mp4\"  #@param {type:\"string\"}\n",
        "convert_all = \"No\" #@param [\"Yes\", \"No\"]\n",
        "number_of_files = 2 # @param {type:\"integer\"}\n",
        "\n",
        "path = \"/content/\" + folder + \"/\"\n",
        "for filename in os.listdir(path):\n",
        "    if filename.endswith(extension):\n",
        "        data.append(filename)\n",
        "        filename2 = filename + \".\" + convert_to\n",
        "        oo.append(filename2)\n",
        "\n",
        "print(data)\n",
        "print(oo)\n",
        "print(\" \")\n",
        "\n",
        "if convert_all == \"Yes\":\n",
        "  iter = range(len(data))\n",
        "else:\n",
        "  iter = range(number_of_files)\n",
        "\n",
        "path0 = \"/content/\" + output_folder + \"/\"\n",
        "try:\n",
        "  os.makedirs(path0, exist_ok = True)\n",
        "except OSError as error:\n",
        "  print(\"Directory can not be created.\")\n",
        "\n",
        "for i in iter:\n",
        "  print (data[i])\n",
        "  path1 = path + data[i]\n",
        "  path2 = path0 + oo[i]\n",
        "  !ffmpeg -i \"$path1\" -c:v libx264 -c:a aac \"$path2\"\n",
        "  print(\" \")"
      ],
      "metadata": {
        "id": "lwBGB7kgHeB8",
        "outputId": "54d71138-3682-43db-93c5-81b701096d1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ben.10.Ultimate.Alien.S01E09.Hero.Time.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E18.The.Enemy.of.My.Enemy.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E13.Deep.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E11.Map.of.Infinity.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E06.Too.Hot.to.Handle.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E04.Video.Games.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E03.Hit.Em.Where.They.Live.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E19.Absolute.Power.1.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E10.Ultimate.Aggregor.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E16.The.Forge.of.Creation.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E01.Fame.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E02.Duped.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E15.Perplexahedron.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E07.Andreas.Fault.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E05.Escape.from.Aggregor.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E12.Reflected.Glory.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E08.Fused.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E14.Where.the.Magic.Happens.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E20.Absolute.Power.2.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv', 'Ben.10.Ultimate.Alien.S01E17.Nor.Iron.Bars.a.Cage.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv']\n",
            "['Ben.10.Ultimate.Alien.S01E09.Hero.Time.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E18.The.Enemy.of.My.Enemy.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E13.Deep.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E11.Map.of.Infinity.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E06.Too.Hot.to.Handle.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E04.Video.Games.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E03.Hit.Em.Where.They.Live.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E19.Absolute.Power.1.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E10.Ultimate.Aggregor.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E16.The.Forge.of.Creation.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E01.Fame.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E02.Duped.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E15.Perplexahedron.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E07.Andreas.Fault.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E05.Escape.from.Aggregor.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E12.Reflected.Glory.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E08.Fused.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E14.Where.the.Magic.Happens.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E20.Absolute.Power.2.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4', 'Ben.10.Ultimate.Alien.S01E17.Nor.Iron.Bars.a.Cage.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4']\n",
            "Ben.10.Ultimate.Alien.S01E09.Hero.Time.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv\n",
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, matroska,webm, from '/content/Torrent/Ben.10.Ultimate.Alien.S01.1080p.HMAX.WEBRip.DD.2.0.x265-EDGE2020/Ben.10.Ultimate.Alien.S01E09.Hero.Time.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv':\n",
            "  Metadata:\n",
            "    encoder         : libebml v1.4.2 + libmatroska v1.6.4\n",
            "    creation_time   : 2023-03-09T08:24:21.000000Z\n",
            "  Duration: 00:22:35.49, start: 0.000000, bitrate: 2276 kb/s\n",
            "  Stream #0:0: Video: hevc (Main 10), yuv420p10le(tv, bt709), 1920x1080, SAR 1:1 DAR 16:9, 29.97 fps, 29.97 tbr, 1k tbn, 29.97 tbc (default)\n",
            "  Stream #0:1(eng): Audio: ac3, 48000 Hz, stereo, fltp, 384 kb/s\n",
            "  Stream #0:2(eng): Subtitle: subrip (default)\n",
            "    Metadata:\n",
            "      title           : \n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (hevc (native) -> h264 (libx264))\n",
            "  Stream #0:1 -> #0:1 (ac3 (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x5bd8a2d9f1c0] \u001b[0musing SAR=1/1\n",
            "\u001b[1;36m[libx264 @ 0x5bd8a2d9f1c0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5bd8a2d9f1c0] \u001b[0mprofile High 10, level 4.0, 4:2:0, 10-bit\n",
            "\u001b[1;36m[libx264 @ 0x5bd8a2d9f1c0] \u001b[0m264 - core 163 r3060 5db6aa6 - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=81 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/S1/Ben.10.Ultimate.Alien.S01E09.Hero.Time.1080p.HMAX.WEBRip.DD.2.0.H.265.-EDGE2020.mkv.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p10le(tv, bt709, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 29.97 fps, 30k tbn (default)\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6Q0bvjs2pt41",
        "jt_RqPgONgLl",
        "k-mB4NsurqE3",
        "M3x1DpmWjwZ3",
        "aFulYXtSZCuB",
        "TQsbRfkqPOo4",
        "6fMvdFDQNoY5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}